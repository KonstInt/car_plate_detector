{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29742e18-0f55-41bc-b6da-8e08769409d3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.layers import (\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    Conv2DTranspose,\n",
    "    Concatenate,\n",
    "    LeakyReLU,\n",
    "    Dropout,\n",
    ")\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc5ffd-9f3b-44db-8b3a-f4d8113ac047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#преобразуем папку в tfrecord\n",
    "#приводит количество рамок к целевому значению\n",
    "goal = 10\n",
    "\n",
    "fn = \"datasource/annotations/\"\n",
    "#формируем список всех xml файлов в папке\n",
    "p = [fn + '/' + f for f in listdir(fn) if isfile(join(fn, f)) and f[-1] == 'l'] \n",
    "print(p[:5])\n",
    "\n",
    "    \n",
    "def load_img(img):\n",
    "    img = tf.io.read_file(\"datasource/images/\"+img)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32)/256\n",
    "    img = tf.image.resize(img,(128,128))\n",
    "    return img\n",
    "    \n",
    "#создаем запись\n",
    "writer = tf.io.TFRecordWriter('bounding_box_dataset.tfrecord')\n",
    "\n",
    "\n",
    "\n",
    "for xml in p:\n",
    "    tree = ET.parse(xml) #адрес файла\n",
    "    root=tree.getroot()   #парсим\n",
    "    num_objects = len(root)-4\n",
    "    cords = []\n",
    "    w = int(root[2][0].text) #ширина x\n",
    "    h = int(root[2][1].text) #высота y\n",
    "    \n",
    "    positions = []\n",
    "    p = 0\n",
    "    while len(positions)<goal:\n",
    "        positions.append(p)\n",
    "        p+=1\n",
    "        if p==num_objects:\n",
    "            p = 0\n",
    "    \n",
    "    for num in positions:\n",
    "        object_cords = []\n",
    "        #нормализуем координаты от -1 до 1, опираясь на исходные координаты\n",
    "        object_cords.append(int(root[num+4][5][0].text)/w*2-1)\n",
    "        object_cords.append(int(root[num+4][5][1].text)/h*2-1)\n",
    "        object_cords.append(int(root[num+4][5][2].text)/w*2-1)\n",
    "        object_cords.append(int(root[num+4][5][3].text)/h*2-1)\n",
    "        cords.append(object_cords)\n",
    "\n",
    "    img = load_img(root[1].text)\n",
    "    #готовим данные, представляем в байтовом виде\n",
    "    serialized_img = tf.io.serialize_tensor(img).numpy()\n",
    "    serialized_cords = tf.io.serialize_tensor(cords).numpy()\n",
    "    #собираем экзепмляр\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'img': tf.train.Feature(bytes_list=tf.train.BytesList(value=[serialized_img])),\n",
    "        'cords': tf.train.Feature(bytes_list=tf.train.BytesList(value=[serialized_cords]))\n",
    "    }))\n",
    "\n",
    "    #записываем в запись\n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1736086-2363-41b4-a298-10d27334de0a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#преобразуем папку в tfrecord для классификарора\n",
    "import random\n",
    "namespace = {'NOTHING': 0, 'licence': 1 }\n",
    "\n",
    "fn = \"datasource/annotations/\"\n",
    "#формируем список всех xml файлов в папке\n",
    "p = [fn + '/' + f for f in listdir(fn) if isfile(join(fn, f)) and f[-1] == 'l'] \n",
    "\n",
    "    \n",
    "def load_img(img):\n",
    "    img = tf.io.read_file(\"datasource/images/\"+img)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32)/256\n",
    "    img = tf.image.resize(img,(1024,1024))\n",
    "    return img\n",
    "    \n",
    "#создаем запись\n",
    "writer = tf.io.TFRecordWriter('classifier_dataset.tfrecord')\n",
    "\n",
    "def saveinrecord(img, name):\n",
    "    #готовим данные, представляем в байтовом виде\n",
    "    serialized_img = tf.io.serialize_tensor(img).numpy()\n",
    "    serialized_name = tf.io.serialize_tensor(name).numpy()\n",
    "    #собираем экзепмляр\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'img': tf.train.Feature(bytes_list=tf.train.BytesList(value=[serialized_img])),\n",
    "        'name': tf.train.Feature(bytes_list=tf.train.BytesList(value=[serialized_name]))\n",
    "    }))\n",
    "\n",
    "    #записываем в запись\n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "for xml in p:\n",
    "    tree = ET.parse(xml) #адрес файла\n",
    "    root=tree.getroot()   #парсим\n",
    "    num_objects = len(root)-4\n",
    "    \n",
    "    w = int(root[2][0].text) #ширина x\n",
    "    h = int(root[2][1].text) #высота y\n",
    "    \n",
    "    img = load_img(root[1].text)\n",
    "    for num in range(num_objects):\n",
    "        xmin = tf.clip_by_value(int(int(root[num+4][5][0].text)/w*1024), 0, 1024)\n",
    "        ymin = tf.clip_by_value(int(int(root[num+4][5][1].text)/h*1024), 0, 1024)\n",
    "        xmax = tf.clip_by_value(int(int(root[num+4][5][2].text)/w*1024), 0, 1024)\n",
    "        ymax = tf.clip_by_value(int(int(root[num+4][5][3].text)/h*1024), 0, 1024)\n",
    "        \n",
    "        \n",
    "        offset_height = ymin\n",
    "        offset_width = xmin\n",
    "        \n",
    "        target_height = ymax - ymin \n",
    "        target_width = xmax - xmin \n",
    "\n",
    "        cropped = tf.image.crop_to_bounding_box(img, offset_height, offset_width, target_height, target_width)\n",
    "        cropped = tf.image.resize(cropped,(128,128))\n",
    "        \n",
    "        name = namespace[root[num+4][0].text]\n",
    "        \n",
    "        saveinrecord(cropped, name)\n",
    "        \n",
    "    #создадим и рамки фона\n",
    "    counter = 0\n",
    "    goal = 5\n",
    "    \n",
    "    while counter < goal:\n",
    "        #сгенерим случайные координаты рамки\n",
    "        gxmin = random.randint(1, 900)\n",
    "        gymin = random.randint(1, 900)\n",
    "        gxsize = random.randint(10, 100)\n",
    "        gysize = random.randint(10, 100)\n",
    "        \n",
    "        gxmax = gxmin + gxsize\n",
    "        gymax = gymin + gysize\n",
    "        \n",
    "        #а вдруг рамка пересекается с реальной?\n",
    "        notintersect = True\n",
    "        \n",
    "        for num in range(num_objects):\n",
    "            xmin = tf.clip_by_value(int(int(root[num+4][5][0].text)/w*1024), 0, 1024)\n",
    "            ymin = tf.clip_by_value(int(int(root[num+4][5][1].text)/h*1024), 0, 1024)\n",
    "            xmax = tf.clip_by_value(int(int(root[num+4][5][2].text)/w*1024), 0, 1024)\n",
    "            ymax = tf.clip_by_value(int(int(root[num+4][5][3].text)/h*1024), 0, 1024)\n",
    "            \n",
    "            x_overlap = tf.maximum(0, tf.minimum(gxmax, xmax) - tf.maximum(gxmin, xmin))\n",
    "            y_overlap = tf.maximum(0, tf.minimum(gymax, ymax) - tf.maximum(gymin, ymin))\n",
    "            if x_overlap > 0 and y_overlap>0:\n",
    "                notintersect = False\n",
    "                break\n",
    "                \n",
    "        if notintersect:\n",
    "            cropped = tf.image.crop_to_bounding_box(img, gymin, gxmin, gysize, gxsize)\n",
    "            cropped = tf.image.resize(cropped,(128,128)) \n",
    "            name = 0\n",
    "            saveinrecord(cropped, name)\n",
    "            counter+=1\n",
    "            \n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd9375-25ab-4ce0-a8b2-48aea8518e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#прочитаем запись\n",
    "dataset = tf.data.TFRecordDataset('classifier_dataset.tfrecord')\n",
    "\n",
    "\n",
    "def parse_record(record):\n",
    "    #нужно описать приходящий экземпляр\n",
    "    #имена элементов как при записи\n",
    "    feature_description = {\n",
    "        'img': tf.io.FixedLenFeature([], tf.string),\n",
    "        'name': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    parsed_record = tf.io.parse_single_example(record, feature_description)\n",
    "    img = tf.io.parse_tensor(parsed_record['img'], out_type=tf.float32)\n",
    "    name = tf.io.parse_tensor(parsed_record['name'], out_type=tf.int32)\n",
    "    return img, name\n",
    "\n",
    "#пройдемся по записи и распакуем ее\n",
    "dataset = dataset.map(parse_record)\n",
    "\n",
    "#что-нибудь выведем\n",
    "for i, c in dataset.take(1):\n",
    "    print(i.shape)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756582d-276d-49c5-80af-98dfb1918e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#прочитаем запись\n",
    "dataset = tf.data.TFRecordDataset('bounding_box_dataset.tfrecord')\n",
    "\n",
    "\n",
    "def parse_record(record):\n",
    "    #нужно описать приходящий экземпляр\n",
    "    #имена элементов как при записи\n",
    "    feature_description = {\n",
    "        'img': tf.io.FixedLenFeature([], tf.string),\n",
    "        'cords': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    parsed_record = tf.io.parse_single_example(record, feature_description)\n",
    "    img = tf.io.parse_tensor(parsed_record['img'], out_type=tf.float32)\n",
    "    cords = tf.io.parse_tensor(parsed_record['cords'], out_type=tf.float32)\n",
    "    return img, cords\n",
    "\n",
    "#пройдемся по записи и распакуем ее\n",
    "dataset = dataset.map(parse_record)\n",
    "\n",
    "#еще раз проверим\n",
    "for i, c in dataset.take(10):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = plt.subplot(3, 1, 1)\n",
    "    i = i.numpy()\n",
    "    c = c.numpy()\n",
    "    c = (c+1)/2*128 #обратно из от -1...1 к 0...64\n",
    "    c = c.astype(np.int16)  #для opencv\n",
    "    for bb in c:\n",
    "        i = cv2.rectangle(i ,(bb[0] ,bb[1] ),(bb[2], bb[3]),(1,0,0),1)\n",
    "    plt.imshow(i)\n",
    "    plt.show()\n",
    "    print(c)\n",
    "\n",
    "dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE).batch(32).shuffle(40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
